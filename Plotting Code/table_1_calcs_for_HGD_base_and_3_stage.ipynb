{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd7fcb3",
   "metadata": {},
   "source": [
    "Calculate Training Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9348edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Grid (1 Config) ---\n",
      "Config: 70 epochs, BS=256\n",
      "Calculation: 196 steps/epoch * 70 epochs\n",
      "Total Steps: 13,720\n",
      "\n",
      "--- 3-Stage Grid Search ---\n",
      "  Stage 1: 27 configs x 20 eps x 196 steps/ep\n",
      "           = 105,840 steps\n",
      "  Stage 2: 27 configs x 20 eps x 196 steps/ep\n",
      "           = 105,840 steps\n",
      "  Stage 3: 27 configs x 30 eps x 196 steps/ep\n",
      "           = 158,760 steps\n",
      "Total Steps: 370,440\n",
      "\n",
      "--- HDG ---\n",
      "Total Steps: 27,440\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Method                    | Total Steps     | Relative Cost  \n",
      "------------------------------------------------------------\n",
      "Random Grid (1 run)       | 13,720          | 1.0x           \n",
      "PBT                       | 136,850         | 10.0x          \n",
      "3-Stage Grid              | 370,440         | 27.0x          \n",
      "HDG                       | 27,440          | 2.0x           \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# ==========================================\n",
    "# 1. GLOBAL CONSTANTS & ASSUMPTIONS\n",
    "# ==========================================\n",
    "\n",
    "# CIFAR-10 Training Set Size\n",
    "N_TRAIN_SAMPLES = 50_000 \n",
    "\n",
    "def calculate_steps_per_epoch(n_samples, batch_size):\n",
    "    \"\"\"Calculates optimizer steps per epoch given dataset size and batch size.\"\"\"\n",
    "    # Assuming drop_last=False (standard) -> usage of ceil\n",
    "    return math.ceil(n_samples / batch_size)\n",
    "\n",
    "# ==========================================\n",
    "# 2. METHOD CALCULATORS\n",
    "# ==========================================\n",
    "\n",
    "def calc_standard_training(name, epochs, batch_size):\n",
    "    \"\"\"\n",
    "    Calculates steps for 'Random Grid' or 'Base' (Single Model).\n",
    "    Methodology: Simple sum of updates for one model.\n",
    "    \"\"\"\n",
    "    steps_per_epoch = calculate_steps_per_epoch(N_TRAIN_SAMPLES, batch_size)\n",
    "    total_steps = steps_per_epoch * epochs\n",
    "    \n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Config: {epochs} epochs, BS={batch_size}\")\n",
    "    print(f\"Calculation: {steps_per_epoch} steps/epoch * {epochs} epochs\")\n",
    "    print(f\"Total Steps: {total_steps:,}\\n\")\n",
    "    return total_steps\n",
    "\n",
    "def calc_pbt(name, epochs, batch_size, population_size):\n",
    "    \"\"\"\n",
    "    Calculates steps for Population Based Training (PBT).\n",
    "    Methodology: Sum of steps taken by ALL population members.\n",
    "    Cost = (Steps per Member) * (Population Size)\n",
    "    \"\"\"\n",
    "    steps_per_epoch = calculate_steps_per_epoch(N_TRAIN_SAMPLES, batch_size)\n",
    "    steps_per_member = steps_per_epoch * epochs\n",
    "    total_steps = steps_per_member * population_size\n",
    "    \n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Config: {epochs} epochs, BS={batch_size}, Pop={population_size}\")\n",
    "    print(f\"Total Steps: {total_steps:,}\\n\")\n",
    "    return total_steps\n",
    "\n",
    "def calc_multistage_grid(name, stage_details, batch_size):\n",
    "    \"\"\"\n",
    "    Calculates steps for a 3-Stage Grid Search (e.g., Successive Halving or Coarse-to-Fine).\n",
    "    \n",
    "    stage_details: List of tuples [(num_configs, epochs_run), ...]\n",
    "    \n",
    "    Example for Successive Halving:\n",
    "    Stage 1: Start with 27 configs, run for 3 epochs.\n",
    "    Stage 2: Keep top 9 configs, run for 9 MORE epochs.\n",
    "    Stage 3: Keep top 3 configs, run for 27 MORE epochs.\n",
    "    Input: [(27, 3), (9, 9), (3, 27)]\n",
    "    \"\"\"\n",
    "    total_steps = 0\n",
    "    print(f\"--- {name} ---\")\n",
    "    steps_per_epoch = calculate_steps_per_epoch(N_TRAIN_SAMPLES, batch_size)\n",
    "    \n",
    "    for i, (num_configs, epochs) in enumerate(stage_details):\n",
    "        # Calculate cost for this specific stage\n",
    "        stage_cost = num_configs * epochs * steps_per_epoch\n",
    "        total_steps += stage_cost\n",
    "        \n",
    "        print(f\"  Stage {i+1}: {num_configs} configs x {epochs} eps x {steps_per_epoch} steps/ep\")\n",
    "        print(f\"           = {stage_cost:,} steps\")\n",
    "\n",
    "    print(f\"Total Steps: {total_steps:,}\\n\")\n",
    "    return total_steps\n",
    "\n",
    "def calc_hdg(name, epochs, batch_size, hypergrad_calc_every_k_steps=1):\n",
    "    \"\"\"\n",
    "    Calculates steps for Hyperparameter Gradient (HDG).\n",
    "    Methodology: Parameter Updates + Hyperparameter Updates.\n",
    "    \"\"\"\n",
    "    steps_per_epoch = calculate_steps_per_epoch(N_TRAIN_SAMPLES, batch_size)\n",
    "    param_updates = steps_per_epoch * epochs\n",
    "    hypergrad_updates = math.floor(param_updates / hypergrad_calc_every_k_steps)\n",
    "    total_steps = param_updates + hypergrad_updates\n",
    "    \n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Total Steps: {total_steps:,}\\n\")\n",
    "    return total_steps\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION WITH REPORTED VALUES\n",
    "# ==========================================\n",
    "\n",
    "# 1. RANDOM GRID / BASE (Single Config Cost)\n",
    "steps_random = calc_standard_training(\n",
    "    name=\"Random Grid (1 Config)\", \n",
    "    epochs=70,      \n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# 3. 3-STAGE GRID SEARCH\n",
    "# Modify the tuples below to match your exact experiment.\n",
    "# Format: (number_of_configurations_running, number_of_epochs_they_run_for)\n",
    "# NOTE: If Stage 2 continues previous training, put only the *additional* epochs here.\n",
    "stage_schedule = [\n",
    "    (27, 20),   # Stage 1: 27 configs run for 20 epochs\n",
    "    (27,  20),   # Stage 2: 27 configs continue for 20 more epochs\n",
    "    (27,  30)    # Stage 3: 27 configs continue for 30 more epochs (Total 70)\n",
    "]\n",
    "\n",
    "steps_3stage_grid = calc_multistage_grid(\n",
    "    name=\"3-Stage Grid Search\",\n",
    "    stage_details=stage_schedule,\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# 4. HDG\n",
    "steps_hdg = calc_hdg(\n",
    "    name=\"HDG\", \n",
    "    epochs=70, \n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. SUMMARY TABLE PRINT\n",
    "# ==========================================\n",
    "print(\"=== FINAL COMPARISON ===\")\n",
    "print(f\"{'Method':<25} | {'Total Steps':<15} | {'Relative Cost':<15}\")\n",
    "print(\"-\" * 60)\n",
    "base_cost = steps_random # Using single run as base unit\n",
    "for name, cost in [(\"Random Grid (1 run)\", steps_random), (\"PBT\", steps_pbt), (\"3-Stage Grid\", steps_3stage_grid), (\"HDG\", steps_hdg)]:\n",
    "    relative = f\"{cost / base_cost:.1f}x\"\n",
    "    print(f\"{name:<25} | {cost:<15,} | {relative:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e6658fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ACCURACY RESULTS (95% CI) ===\n",
      "Method                    | N   | Mean Acc   | 95% CI     | Formatted\n",
      "---------------------------------------------------------------------------\n",
      "Random Grid (1 Config)    | 5   | 85.02    % | ± 0.24     | 85.02% ± 0.24%\n",
      "3-Stage Grid Search       | 1   | 80.29    % | ± 0.00     | 80.29% ± 0.00%\n",
      "HDG                       | 5   | 69.62    % | ± 0.56     | 69.62% ± 0.56%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# ==========================================\n",
    "# 1. HELPER FUNCTION\n",
    "# ==========================================\n",
    "\n",
    "def compute_stats(accuracies, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculates mean and the 95% Confidence Interval margin of error.\n",
    "    \n",
    "    Args:\n",
    "        accuracies (list or np.array): List of validation accuracies (e.g., [85.1, 84.9, ...])\n",
    "        confidence (float): The confidence level (default 0.95)\n",
    "        \n",
    "    Returns:\n",
    "        dict: {'mean': float, 'error': float, 'formatted': str}\n",
    "    \"\"\"\n",
    "    a = np.array(accuracies)\n",
    "    n = len(a)\n",
    "    \n",
    "    # 1. Calculate Mean\n",
    "    m = np.mean(a)\n",
    "    \n",
    "    # 2. Calculate Margin of Error\n",
    "    if n < 2:\n",
    "        # Cannot compute std dev with 1 sample\n",
    "        h = 0.0\n",
    "    else:\n",
    "        # Standard Error of the Mean (SE)\n",
    "        se = st.sem(a) \n",
    "        \n",
    "        # Critical Value (T-statistic for small samples, converges to 1.96 for large N)\n",
    "        # ppf is the \"Percent Point Function\" (inverse of CDF)\n",
    "        h = se * st.t.ppf((1 + confidence) / 2., n-1)\n",
    "\n",
    "    return {\n",
    "        \"mean\": m,\n",
    "        \"error\": h,\n",
    "        \"n\": n,\n",
    "        \"formatted\": f\"{m:.2f}% ± {h:.2f}%\"\n",
    "    }\n",
    "\n",
    "# ==========================================\n",
    "# 2. INPUT DATA (Replace with your actual lists)\n",
    "# ==========================================\n",
    "\n",
    "# Example: Accuracies collected from multiple random seeds\n",
    "\n",
    "data = {\n",
    "    \"Random Grid (1 Config)\": [84.68, 85.05, 85.13, 85.13, 85.13],    # ~5 seeds\n",
    "    \"3-Stage Grid Search\":    [80.29],           # ~1 seed\n",
    "    \"HDG\":                    [69.46, 70.37, 69.61, 69.14, 69.54]     # ~5 seeds\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 3. GENERATE TABLE\n",
    "# ==========================================\n",
    "\n",
    "print(\"=== ACCURACY RESULTS (95% CI) ===\")\n",
    "print(f\"{'Method':<25} | {'N':<3} | {'Mean Acc':<10} | {'95% CI':<10} | {'Formatted'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for method, acc_list in data.items():\n",
    "    stats = compute_stats(acc_list)\n",
    "    \n",
    "    # Unpack for cleaner print statement\n",
    "    n = stats['n']\n",
    "    mean = stats['mean']\n",
    "    err = stats['error']\n",
    "    fmt = stats['formatted']\n",
    "    \n",
    "    print(f\"{method:<25} | {n:<3} | {mean:<9.2f}% | ± {err:<8.2f} | {fmt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
